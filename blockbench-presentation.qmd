---
title: "BLOCKBENCH: A Framework for Analyzing Private Blockchains"
subtitle: "Research Paper Presentation"
author: Cesaire Tobias
date: 2 May 2025
format:
  revealjs:
    theme: [default, custom.scss]
    self-contained: true
    embed-resources: true
    touch: true
    controls: true
    slide-number: c/t
    footer: Financial Software Engineering (ECO5040S) - Assignment 1
    center-title-slide: true
    highlight-style: a11y
    height: 1080
    width: 1920
    template-partials:
      - title-slide.html
    include-in-header:
      - text: |
          <script src="https://unpkg.com/mermaid@9/dist/mermaid.min.js"></script>
    auto-slide: false
execute:
  echo: false
  eval: true
  freeze: auto
---

# Presentation Overview {.center}

1. Introduction to Private Blockchains
2. The Need for BLOCKBENCH
3. Framework Architecture
4. Benchmark Workloads
5. Evaluation Methodology
6. Performance Results
7. Key Findings
8. Implications for Industry
9. Future Directions
10. Conclusion

::: notes
BLOCKBENCH - a framework developed by researchers from the National University of Singapore and Zhejiang University for analyzing private blockchain systems. Today we'll explore how this framework helps evaluate blockchain performance and what insights it provides for future development.

We'll begin with a brief introduction to private blockchains, then explore why BLOCKBENCH was needed. We'll examine its architecture, benchmarking approach, and key findings before discussing implications for industries considering blockchain adoption.
:::

# Introduction to Private Blockchains {.center}

- **Private Blockchains**: Permissioned networks where participants are identified
- **Target Applications**: 
  - Enterprise systems
  - Consortium networks
  - Supply chains
- **Key Platforms**: 
  - Ethereum
  - Hyperledger Fabric
  - Parity

[For more on Blockchain Types, see Appendix](#blockchain-types)


::: notes
Unlike public blockchains like Bitcoin where anyone can participate, private blockchains operate in controlled environments with known participants. They're designed for enterprise applications like supply chain management, financial services, and healthcare records. The three platforms evaluated in the paper—Ethereum, Hyperledger Fabric, and Parity—represent different architectural approaches to private blockchain implementation.
:::

# The Need for BLOCKBENCH {.center}

- Lack of Standard Evaluation Framework
- Difficult to Compare Different Systems
- Gap Between Industry Claims and Reality
- No Baseline Comparison with Traditional Databases

::: notes
Before BLOCKBENCH, there was no standardized way to evaluate and compare blockchain systems. Companies and organizations had to rely on vendor claims or conduct their own assessments, which were often inconsistent or incomplete. BLOCKBENCH fills this gap by providing a systematic framework that enables apples-to-apples comparisons not only between blockchain platforms but also against traditional database systems that blockchain might potentially replace.
:::

# Framework Architecture {.center}

::: {.mermaid-container style="display: flex; justify-content: center; align-items: center; height: 70vh;"}
```{mermaid}
flowchart TD
    %% Main title
    title["BlockBench Framework Architecture"]
    
    %% Main Layers
    WL[Workload Layer\nYCSB, Smallbank, EtherId, DoNothing]
    EE[Execution Engine Layer\nSmart Contracts, Virtual Machines]
    CL[Consensus Layer\nPoW, PBFT, PoS, Raft]
    DM[Data Model Layer\nKey-Value Store, Account/State Model]
    BP[Blockchain Platforms\nEthereum, Hyperledger Fabric, Parity, Quorum]
    
    %% Left side - Drivers
    DI[Drivers & Interfaces]
    D1[Macro Benchmarks]
    D2[Micro Benchmarks]
    D3[Smart Contracts]
    D4[Client APIs]
    D5[Asynchronous]
    
    %% Right side - Metrics
    PM[Performance Metrics]
    M1[Throughput]
    M2[Latency]
    M3[Scalability]
    M4[Fault Tolerance]
    M5[Security]
    
    %% Connections for main flow
    title --> WL
    WL --> EE
    EE --> CL
    CL --> DM
    DM --> BP
    
    %% Connections for drivers
    DI --> D1
    DI --> D2
    DI --> D3
    DI --> D4
    DI --> D5
    
    D1 --- WL
    D2 --- EE
    D3 --- EE
    D4 --- CL
    D5 --- DM
    
    %% Connections for metrics
    PM --> M1
    PM --> M2
    PM --> M3
    PM --> M4
    PM --> M5
    
    M1 --- WL
    M2 --- EE
    M3 --- CL
    M4 --- CL
    M5 --- DM
    
    %% Styling
    classDef workload fill:#d1e7dd,stroke:#198754,stroke-width:2px
    classDef execution fill:#cfe2ff,stroke:#0d6efd,stroke-width:2px
    classDef consensus fill:#f8d7da,stroke:#dc3545,stroke-width:2px
    classDef datamodel fill:#fff3cd,stroke:#ffc107,stroke-width:2px
    classDef platforms fill:#e2e3e5,stroke:#6c757d,stroke-width:2px
    classDef drivers fill:#e2e3e5,stroke:#6c757d,stroke-width:1px
    classDef metrics fill:#e2e3e5,stroke:#6c757d,stroke-width:1px
    classDef title font-size:18px,font-weight:bold
    
    class WL workload
    class EE execution
    class CL consensus
    class DM datamodel
    class BP platforms
    class DI,D1,D2,D3,D4,D5 drivers
    class PM,M1,M2,M3,M4,M5 metrics
    class title title
```
:::

::: notes
- **Layered Approach**:
  - Consensus Layer
  - Data Model Layer
  - Execution Layer
- **Benchmark Interface**
- **Metrics Focus**: 
  - Throughput
  - Latency
  - Scalability
  - Fault Tolerance
BLOCKBENCH uses a layered approach to evaluate blockchain systems, focusing on three critical layers: consensus mechanisms for transaction agreement, data models for state management, and execution environments for smart contracts. This architecture allows for targeted benchmarking at each layer while also enabling holistic system evaluation. The framework collects key metrics like throughput (transactions per second), latency (time to confirmation), scalability (performance as network grows), and fault tolerance (resilience to node failures).
:::

# Benchmark Workloads {.center}

::: {.table-container style="display: flex; justify-content: center; align-items: center; height: 60vh;"}
| Workload | Description | Tests |
|----------|-------------|-------|
| **YCSB** | Key-value operations | Read/write/scan operations |
| **Smallbank** | Banking transactions | Account transfers, balance checks |
| **EtherId** | Name registration | Complex state operations |
| **Donothing** | Empty blocks | Consensus overhead |
:::

::: notes
The researchers designed four workloads to stress different aspects of blockchain systems. YCSB tests basic data operations. Smallbank simulates banking transactions to evaluate consistency and isolation. EtherId tests complex smart contract operations through domain name registration scenarios. The Donothing benchmark isolates consensus overhead by processing empty blocks, revealing the baseline cost of the consensus protocol itself.
:::

# Evaluation Methodology {.center}

::: {.columns}
::: {.column width="50%"}
- **Systems Under Test**:
  - Ethereum (PoW)
  - Hyperledger Fabric (PBFT)
  - Parity (PoA)
  - H-Store (traditional distributed database)
- **Controlled Environment**: 48-node cluster
- **Statistical Rigor**: Multiple runs, confidence intervals
- **Parameter Optimization**: Each system configured optimally
:::

::: {.column width="50%" style="display: flex; justify-content: center; align-items: center;"}
```{mermaid}
graph TD
    A[Setup] --> B[Systems: Ethereum, Hyperledger, Parity, H-Store]
    B --> C[48-node Cluster]
    C --> D[Optimize Parameters]
    D --> E[Run Benchmarks]
    E --> F[Collect Metrics]
    F --> G[Statistical Analysis]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
    style E fill:#03a9f4,stroke:#0288d1,color:#fff
    style G fill:#03a9f4,stroke:#0288d1,color:#fff
```
:::
:::

::: notes
The evaluation was conducted on a 48-node cluster, allowing for tests with varying network sizes. Each system was configured for optimal performance before testing, ensuring fair comparison. The researchers employed statistical rigor by running each test multiple times with different random seeds and reporting results with confidence intervals. The inclusion of H-Store provides a crucial baseline for understanding how blockchain systems compare to traditional technology.
:::

# Performance Results: Throughput {.center}

::: {.columns}
::: {.column width="40%"}
- **Blockchain vs Database**:
  - H-Store: 10,000+ TPS
  - Private Blockchains: 1,000-3,000 TPS peak
- **Platform Comparison**:
  - Ethereum: Moderate but consistent
  - Hyperledger: Higher peaks, more variability
  - Parity: Performance varies by workload
:::

::: {.column width="60%" style="display: flex; justify-content: center; align-items: center;"}
```{python}
import plotly.graph_objects as go
fig = go.Figure(data=[
    go.Bar(name='Throughput (TPS)', x=['H-Store', 'Ethereum', 'Hyperledger', 'Parity'],
           y=[10000, 2000, 3000, 2500],
           marker_color=['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3'])
])
fig.update_layout(
    autosize=True,
    title={'text': 'Throughput Comparison', 'font': {'size': 16}},
    xaxis_title={'text': 'System', 'font': {'size': 12}},
    yaxis_title={'text': 'Transactions per Second', 'font': {'size': 12}},
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20),
    plot_bgcolor='rgba(240, 240, 240, 0.8)'
)
fig.update_yaxes(gridcolor='rgba(200, 200, 200, 0.2)')
fig.show()
```
:::
:::

::: notes
The throughput results reveal a significant performance gap between blockchain systems and traditional databases. H-Store consistently achieved over 10,000 transactions per second, while blockchain systems peaked between 1,000 and 3,000 TPS. Hyperledger showed higher peak throughput but with more variability. Ethereum was consistent, while Parity's performance depended on workload type.
:::

# Performance Results: Latency {.center}

::: {.columns}
::: {.column width="40%"}
- **Transaction Confirmation Time**:
  - H-Store: Milliseconds
  - Ethereum: 3-10 seconds
  - Hyperledger: 100-800 milliseconds
  - Parity: 200-1000 milliseconds
- **Consensus Protocol Impact**:
  - PoW (Ethereum): Highest latency
  - PBFT (Hyperledger): Lower but scaling issues
  - PoA (Parity): Varies with validator count
:::

::: {.column width="60%" style="display: flex; justify-content: center; align-items: center;"}
```{python}
import plotly.graph_objects as go
fig = go.Figure(data=[
    go.Bar(name='Latency (ms)', 
           x=['H-Store', 'Ethereum', 'Hyperledger', 'Parity'],
           y=[1, 6000, 450, 600],
           marker_color=['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3'],
           text=[f"{y} ms" for y in [1, 6000, 450, 600]],
           textposition='auto')
])
fig.update_layout(
    autosize=True,
    title={'text': 'Latency Comparison (Log Scale)', 'font': {'size': 16}},
    xaxis_title={'text': 'System', 'font': {'size': 12}},
    yaxis_title={'text': 'Latency (ms)', 'font': {'size': 12}},
    yaxis_type="log",
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20),
    plot_bgcolor='rgba(240, 240, 240, 0.8)'
)
fig.update_yaxes(gridcolor='rgba(200, 200, 200, 0.2)')
fig.show()
```
:::
:::

::: notes
Latency results show dramatic differences. Traditional databases commit transactions in milliseconds, while blockchain systems require hundreds of milliseconds to several seconds. Ethereum's Proof of Work has the highest latencies (3-10 seconds). Hyperledger's PBFT is faster but scales poorly. Parity's Proof of Authority varies with validator count.
:::

# Performance Results: Scalability {.center}

::: {.columns}
::: {.column width="40%"}
- **Negative Scalability**:
  - Performance degrades as nodes increase
  - 30-50% reduction when doubling nodes
- **Consensus Bottlenecks**:
  - PBFT: O(n²) message complexity
  - PoW: Network propagation overhead
- **Contrast with Databases**:
  - H-Store: Near-linear scaling (positive)
:::

::: {.column width="60%" style="display: flex; justify-content: center; align-items: center;"}
```{python}
import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scatter(x=[8, 16, 32], y=[3000, 2000, 1100], mode='lines+markers', name='Ethereum'))
fig.add_trace(go.Scatter(x=[8, 16, 32], y=[3500, 2300, 1200], mode='lines+markers', name='Hyperledger'))
fig.add_trace(go.Scatter(x=[8, 16, 32], y=[3200, 2100, 1150], mode='lines+markers', name='Parity'))
fig.add_trace(go.Scatter(x=[8, 16, 32], y=[10000, 10500, 11000], mode='lines+markers', name='H-Store'))
fig.update_layout(
    title={'text': 'Scalability Analysis', 'font': {'size': 16}},
    xaxis_title={'text': 'Number of Nodes', 'font': {'size': 12}},
    yaxis_title={'text': 'Throughput (TPS)', 'font': {'size': 12}},
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20),
    plot_bgcolor='rgba(240, 240, 240, 0.8)'
)
fig.update_yaxes(gridcolor='rgba(200, 200, 200, 0.2)')
fig.show()
```
:::
:::

::: notes
Blockchain systems exhibit negative scalability, with performance degrading by 30-50% when doubling nodes. Hyperledger's PBFT suffers from quadratic message complexity, and Ethereum's PoW faces propagation delays. In contrast, H-Store scales positively, highlighting a key challenge for blockchain adoption.
:::

# Layer-Specific Findings {.center}

::: {.columns}
::: {.column width="40%"}
- **Consensus Layer**: 80-90% of total latency
- **Data Model Layer**:
  - Account-based (Ethereum): Better for read-heavy workloads
  - UTXO-based (Hyperledger): Better for write-intensive applications
- **Execution Layer**:
  - 10-100x overhead compared to native execution
  - Inefficient memory management
  - Limited optimization capabilities
:::

::: {.column width="60%" style="display: flex; justify-content: center; align-items: center;"}
```{python}
import plotly.graph_objects as go
fig = go.Figure(data=[
    go.Pie(labels=['Consensus Layer', 'Data Model Layer', 'Execution Layer'],
           values=[85, 10, 5],
           marker=dict(colors=['#0288d1', '#03a9f4', '#4fc3f7']))
])
fig.update_layout(
    autosize=True,
    title={'text': 'Latency Contribution by Layer', 'font': {'size': 16}},
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20)
)
fig.show()
```
:::
:::

::: notes
The consensus layer dominates latency (80-90%). Ethereum's account-based model suits read-heavy workloads, while Hyperledger's UTXO excels in write-intensive scenarios. The execution layer adds significant overhead (10-100x) due to inefficient virtual machines and memory management.
:::

# Key Findings and Implications {.center}

::: {style="height: 100%; display: flex; flex-direction: column;"}
::: {style="display: flex; height: 40%;"}
- **Performance Gap**: Private blockchains significantly underperform databases
- **Negative Scalability**: Adding nodes decreases performance
- **Execution Inefficiency**: Smart contracts introduce major overhead
- **Consensus Dominance**: Protocol choice is the primary performance determinant
- **Data Model Impact**: Selection affects workload suitability
:::

::: {style="display: flex; justify-content: center; align-items: center; height: 60%;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '18px'}}}%%
graph TD
    A[Key BLOCKBENCH Findings] --> B[Performance Gap]
    A --> C[Negative Scalability]
    A --> D[Execution Inefficiency]
    A --> E[Consensus Dominance]
    A --> F[Data Model Impact]
    B --> B1[10-100x slower than databases]
    C --> C1[Performance decreases with node count]
    D --> D1[Smart contracts add 10-100x overhead]
    E --> E1[Consensus protocol is primary bottleneck]
    F --> F1[Data model should match workload]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
```
:::
:::

::: notes
The research highlights a performance gap with databases, negative scalability, and inefficient smart contract execution. Consensus protocols dominate performance, and data model choice should align with workload needs, impacting enterprise blockchain adoption.
:::

# Implications for Industry {.center}

::: {.table-container style="display: flex; justify-content: center; align-items: center; height: 60vh;"}
| Industry | Requirements | Blockchain Readiness |
|----------|--------------|---------------------|
| Financial Services | High throughput, low latency | Limited - Hybrid solutions recommended |
| Supply Chain | Scalability, moderate throughput | Moderate - Careful design needed |
| Healthcare | Confidentiality, moderate latency | Promising - With optimization |
| Real Estate | Security, lower throughput | Good fit - Current performance adequate |
:::

::: notes
Financial services may need hybrid solutions due to performance limitations. Supply chains require careful scalability design. Healthcare shows promise with optimization, and real estate is a good fit for current blockchain capabilities.
:::

# Conclusion {.center}

::: {.columns}
::: {.column width="50%"}
- **BLOCKBENCH Contribution**: First systematic framework for evaluation
- **Current State**: Promising technology with significant limitations
- **Path Forward**:
  - Consensus protocol innovation
  - Execution optimization
  - Data model hybridization
  - Architecture rethinking
:::

::: {.column width="50%" style="display: flex; justify-content: center; align-items: center;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '18px'}}}%%
graph TD
    A[Path Forward] --> B[Consensus Innovation]
    B --> C[Execution Optimization]
    C --> D[Data Model Hybridization]
    D --> E[Architecture Rethinking]
    B --> B1[Layered protocols]
    C --> C1[JIT compilation]
    D --> D1[Hybrid approaches]
    E --> E1[Database integration]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
```
:::
:::

::: notes
BLOCKBENCH provides a pioneering evaluation framework, revealing blockchain's promise and limitations. Future improvements require consensus innovation, execution optimization, data model hybridization, and architectural rethinking for enterprise adoption.
:::

# Thank You {.center}
Questions?

::: notes
any questions
:::

# Appendix {.appendix .center}

The following slides contain supplementary information including charts, diagrams, references, and detailed results from the paper.

## Additional Resources {.center}
- [Github Repository](https://github.com/ces0491/blockbench-presentation)
- Follow-up resources:
  - [BLOCKBENCH GitHub Repo](github.com/ooibc88/blockbench)
  - [Paper: BLOCKBENCH: A Framework for Analyzing Private Blockchains](#bb-paper)
  - [Running BLOCKBENCH for Ethereum](https://medium.com/@mu7eh7/running-blockbench-for-ethereum-6dca3ed44a35)

## BLOCKBENCH Paper {#bb-paper .center}

<iframe src="https://www.comp.nus.edu.sg/~ooibc/blockbench.pdf" width="100%" height="800px"></iframe>

[View BLOCKBENCH Paper](https://www.comp.nus.edu.sg/~ooibc/blockbench.pdf){target="_blank"}

::: notes
This is the original BLOCKBENCH paper by Dinh et al. (2017). Full citation: Dinh, T. T. A., Wang, J., Chen, G., Liu, R., Ooi, B. C., & Tan, K. L. (2017). BLOCKBENCH: A framework for analyzing private blockchains. In Proceedings of the 2017 ACM International Conference on Management of Data (pp. 1085-1100).
:::

## Blockchain Types {#blockchain-types data-id="blockchain-types" .center}

::: {style="display: flex; justify-content: center; align-items: center; height: 70vh;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '22px'}}}%%
graph TD
    A[Blockchain Types] --> B[Public Blockchain]
    A --> C[Private Blockchain]
    B --> B1[Open Access: Anyone can join]
    B --> B2[Examples: Bitcoin, Ethereum]
    B --> B3[High Decentralization]
    C --> C1[Permissioned: Known participants]
    C --> C2[Examples: Hyperledger, Parity]
    C --> C3[Enterprise Use: Supply chain, finance]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
    style B fill:#03a9f4,stroke:#0288d1,color:#fff
    style C fill:#03a9f4,stroke:#0288d1,color:#fff
```
:::

## Need for Standard Framework {#need-for-standard-framework data-id="need-for-standard-framework" .center}

::: {style="display: flex; justify-content: center; align-items: center; height: 70vh;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '22px'}}}%%
graph TD
    subgraph Current State
        A[Blockchain Systems] --> B[Vendor Claims]
        A --> C[Custom Evaluations]
        B --> D[Inconsistent Metrics]
        C --> D
        D --> E[Limited Comparability]
        D --> F[No Database Benchmark]
        D --> G[Unreliable Insights]
    end
    subgraph With BLOCKBENCH
        H[Blockchain Systems] --> I[BLOCKBENCH Framework]
        I --> J[Standardized Metrics]
        I --> K[Cross-Platform Comparison]
        I --> L[Database Benchmarking]
        I --> M[Objective Insights]
    end
    E & F & G --> N[Need for BLOCKBENCH]
    N --> I
    style I fill:#0288d1,stroke:#0277bd,color:#fff
    style N fill:#03a9f4,stroke:#0288d1,color:#fff
```
:::

## BLOCKBENCH Framework {#blockbench-framework data-id="blockbench-framework" .center}

::: {style="display: flex; justify-content: center; align-items: center; height: 70vh;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '22px'}}}%%
graph TD
    A[BLOCKBENCH Framework] --> B[Consensus Layer]
    A --> C[Data Model Layer]
    A --> D[Execution Layer]
    B --> B1[Transaction Agreement]
    C --> C1[State Management]
    D --> D1[Smart Contract Execution]
    A --> E[Benchmark Interface]
    E --> F[Metrics: Throughput, Latency, Scalability, Fault Tolerance]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
    style E fill:#03a9f4,stroke:#0288d1,color:#fff
```
:::

## Benchmark Workloads Diagram {#benchmark-workloads-diagram data-id="benchmark-workloads-diagram" .center}

::: {style="display: flex; justify-content: center; align-items: center; height: 70vh;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '22px'}}}%%
graph TD
    A[Workloads] --> B[YCSB]
    A --> C[Smallbank]
    A --> D[EtherId]
    A --> E[Donothing]
    B --> B1[Key-value operations]
    C --> C1[Banking transactions]
    D --> D1[Name registration]
    E --> E1[Empty blocks]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
    style B fill:#03a9f4,stroke:#0288d1,color:#fff
    style C fill:#03a9f4,stroke:#0288d1,color:#fff
    style D fill:#03a9f4,stroke:#0288d1,color:#fff
    style E fill:#03a9f4,stroke:#0288d1,color:#fff
```
:::

## Key Findings {#key-findings data-id="key-findings" .center}

::: {style="display: flex; justify-content: center; align-items: center; height: 70vh;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '22px'}}}%%
graph TD
    A[Key Findings] --> B[Performance Gap]
    A --> C[Negative Scalability]
    A --> D[Execution Inefficiency]
    A --> E[Consensus Dominance]
    A --> F[Data Model Impact]
    B --> B1[10-100x slower than databases]
    C --> C1[Performance decreases with node count]
    D --> D1[Smart contracts add 10-100x overhead]
    E --> E1[Consensus protocol is primary bottleneck]
    F --> F1[Data model should match workload]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
```
:::

## Industry Readiness {#industry-readiness data-id="industry-readiness" .center}

::: {.columns}
::: {.column width="30%"}
- **Blockchain Readiness**:
  - Varies by industry needs
  - Requires optimization
:::

::: {.column width="70%" style="display: flex; justify-content: center; align-items: center;"}
```{python}
import plotly.graph_objects as go
categories = ['Throughput', 'Latency', 'Scalability', 'Security']
fig = go.Figure()
fig.add_trace(go.Scatterpolar(r=[3, 3, 2, 5], theta=categories, fill='toself', name='Financial Services'))
fig.add_trace(go.Scatterpolar(r=[4, 4, 3, 4], theta=categories, fill='toself', name='Supply Chain'))
fig.add_trace(go.Scatterpolar(r=[3, 4, 3, 5], theta=categories, fill='toself', name='Healthcare'))
fig.add_trace(go.Scatterpolar(r=[2, 3, 2, 5], theta=categories, fill='toself', name='Real Estate'))
fig.update_layout(
    title={'text': 'Industry Blockchain Readiness', 'font': {'size': 16}},
    polar=dict(radialaxis=dict(visible=True, range=[0, 5])),
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20)
)
fig.show()
```
:::
:::

## YCSB Benchmark Results {#ycsb-benchmark data-id="ycsb-benchmark" .center}

::: {.columns}
::: {.column width="50%"}
- **Read Operations**:
  - Ethereum: 300-400 ops/sec
  - Hyperledger: 1000-1200 ops/sec
  - Parity: 800-900 ops/sec
  - H-Store: 10,000+ ops/sec
- **Write Operations**:
  - 30-50% slower than reads
:::

::: {.column width="50%"}
```{python}
import plotly.graph_objects as go
fig = go.Figure(data=[
    go.Bar(name='Read Ops', x=['Ethereum', 'Hyperledger', 'Parity', 'H-Store'], y=[350, 1100, 850, 10000]),
    go.Bar(name='Write Ops', x=['Ethereum', 'Hyperledger', 'Parity', 'H-Store'], y=[245, 770, 595, 7000])
])
fig.update_layout(
    autosize=True,
    title={'text': 'YCSB Benchmark Results', 'font': {'size': 16}},
    xaxis_title={'text': 'System', 'font': {'size': 12}},
    yaxis_title={'text': 'Operations per Second', 'font': {'size': 12}},
    barmode='group',
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20)
)
fig.show()
```
:::
:::

::: notes
The YCSB benchmark tests key-value operations. Hyperledger led blockchain platforms at 1000-1200 read ops/sec, followed by Parity and Ethereum. H-Store achieved 10,000+ ops/sec. Write operations were 30-50% slower due to consensus and state synchronization overhead.
:::

## Smallbank Benchmark Results {#smallbank-benchmark data-id="smallbank-benchmark"}

::: {.columns}
::: {.column width="50%"}
- **Transaction Throughput**:
  - Ethereum: 250-300 TPS
  - Hyperledger: 700-850 TPS
  - Parity: 500-650 TPS
  - H-Store: 8,000-9,000 TPS
- **Consistency Testing**:
  - All systems maintain ACID properties
:::

::: {.column width="50%"}
::: {.chart-container}
```{python}
import plotly.graph_objects as go
fig = go.Figure(data=[
    go.Bar(name='Throughput (TPS)', x=['Ethereum', 'Hyperledger', 'Parity', 'H-Store'], y=[275, 775, 575, 8500])
])
fig.update_layout(
    autosize=True,
    title={'text': 'Smallbank Benchmark Results', 'font': {'size': 16}},
    xaxis_title={'text': 'System', 'font': {'size': 12}},
    yaxis_title={'text': 'Transactions per Second', 'font': {'size': 12}},
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20)
)
fig.show()
```
:::
:::
:::

::: notes
The Smallbank benchmark tests banking transactions. Hyperledger led with 700-850 TPS, followed by Parity and Ethereum. H-Store achieved 8,000-9,000 TPS. All systems maintained ACID properties, but blockchains incurred overhead for consistency.
:::

## EtherId Benchmark Results {#etherid-benchmark data-id="etherid-benchmark"}

::: {.columns}
::: {.column width="50%"}
- **Complex Smart Contract Operations**:
  - Ethereum: 40-50 ops/sec
  - Hyperledger: 100-150 ops/sec
  - Parity: 70-90 ops/sec
- **Execution Overhead**:
  - VM execution: 40-60%
  - State access: 15-25%
  - Memory management: 10-20%
:::

::: {.column width="50%"}
::: {.chart-container}
```{python}
import plotly.graph_objects as go
fig = go.Figure(data=[
    go.Bar(name='Operations per Second', x=['Ethereum', 'Hyperledger', 'Parity'], y=[45, 125, 80])
])
fig.update_layout(
    autosize=True,
    title={'text': 'EtherId Benchmark Results', 'font': {'size': 16}},
    xaxis_title={'text': 'System', 'font': {'size': 12}},
    yaxis_title={'text': 'Operations per Second', 'font': {'size': 12}},
    font={'size': 10},
    height=450,
    margin=dict(t=50, b=50, l=50, r=20)
)
fig.show()
```
:::
:::
:::

::: notes
The EtherId benchmark tests smart contract operations. Hyperledger processed 100-150 ops/sec, Parity 70-90, and Ethereum 40-50. Virtual machine execution consumed 40-60% of non-consensus time, highlighting inefficiencies in smart contract execution.
:::

## Consensus Protocols {#consensus-protocols data-id="consensus-protocols"}

| Protocol | Description | Used By | Characteristics |
|----------|-------------|---------|----------------|
| PoW | Cryptographic puzzles | Ethereum | High security, high latency |
| PBFT | Multi-round voting | Hyperledger Fabric | Lower latency, O(n²) complexity |
| PoA | Authorized validators | Parity | Low latency, centralization concerns |

::: notes
Proof of Work (PoW) offers strong security but high latency. PBFT is faster but scales poorly. Proof of Authority (PoA) is efficient but more centralized, impacting its suitability for certain applications.
:::

## System Architecture Comparison {#system-architecture data-id="system-architecture"}

::: {style="height: 100%; display: flex; flex-direction: column;"}

::: {style="height: 60%;"}
```{mermaid}
%%{init: {'theme': 'default', 'themeVariables': {'fontSize': '22px'}}}%%
graph TD
    A[Systems] --> B[Ethereum]
    A --> C[Hyperledger]
    A --> D[Parity]
    B --> B1[Account-based]
    B --> B2[PoW]
    B --> B3[EVM]
    C --> C1[UTXO-based]
    C --> C2[PBFT]
    C --> C3[Docker]
    D --> D1[Account-based]
    D --> D2[PoA]
    D --> D3[EVM]
    style A fill:#0288d1,stroke:#0277bd,color:#fff
```
:::

::: {style="height: 40%;"}
| System | Data Model | Consensus | Execution Environment |
|--------|------------|-----------|----------------------|
| Ethereum | Account-based | PoW | EVM |
| Hyperledger | UTXO-based | PBFT | Docker container |
| Parity | Account-based | PoA | EVM |
:::
:::

::: notes
Ethereum and Parity use account-based models with EVM execution, while Hyperledger uses UTXO and Docker. These architectural choices explain performance differences observed in the benchmarks.
:::

## Future Research Directions {#future-research data-id="future-research"}

- **Layered Consensus Protocols**: Tailored consensus per operation
- **Just-In-Time Compilation**: Optimize smart contracts
- **Sharding Approaches**: Improve scalability
- **Hybrid Architecture**: Combine blockchain and databases
- **Hardware Acceleration**: Enhance cryptographic performance

::: notes
Future research should focus on layered consensus, JIT compilation, sharding, hybrid architectures, and hardware acceleration to address blockchain limitations identified by BLOCKBENCH.
:::

## References {#references data-id="references"}

- Dinh, T. T. A., et al. (2017). BLOCKBENCH: A framework for analyzing private blockchains. In Proceedings of the 2017 ACM International Conference on Management of Data (pp. 1085-1100).
- Nakamoto, S. (2008). Bitcoin: A peer-to-peer electronic cash system. Bitcoin.org
- Wood, G. (2014). Ethereum: A secure decentralised generalised transaction ledger. Ethereum project yellow paper.
- Androulaki, E., et al. (2018). Hyperledger fabric: a distributed operating system for permissioned blockchains. In Proceedings of the Thirteenth EuroSys Conference.

::: notes
These references provide background on BLOCKBENCH and the evaluated blockchain systems, including foundational papers on Bitcoin, Ethereum, and Hyperledger Fabric.
:::

## Definitions {#definitions data-id="definitions"}

| Term | Definition |
|------|------------|
| Block | Container of transactions |
| Blockchain | Distributed ledger of linked blocks |
| Consensus Protocol | Mechanism for node agreement |
| EVM | Ethereum Virtual Machine for smart contracts |
| Latency | Time to confirm a transaction |
| Private Blockchain | Permissioned blockchain with known participants |
| Scalability | Performance change with network size |
| Smart Contract | Self-executing blockchain code |
| Throughput | Transactions per second |
| UTXO | Unspent Transaction Output data model |